{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a0bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "204d7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97406e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Documents\n",
    "\n",
    "loader = TextLoader(\"data.txt\")  # <- replace with your file\n",
    "docs = loader.load()\n",
    "# texts = [\n",
    "#     Document(page_content=\"In 2024, Tesla launched a new robotaxi service in California.\"),\n",
    "#     Document(page_content=\"Tesla's 2024 update includes Dojo supercomputer improvements.\"),\n",
    "#     Document(page_content=\"In 2023, Tesla's Cybertruck was announced.\"),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split documents\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5120a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embed and store in vector DB\n",
    "db = Chroma.from_documents(docs, embedding=OpenAIEmbeddings(), persist_directory=\"./db\")\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1585265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tagging Chain (optional metadata extraction)\n",
    "tag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract tags like company and year from the following question:\n",
    "\n",
    "{query}\n",
    "\"\"\")\n",
    "tag_chain = tag_prompt | ChatOpenAI(temperature=0) | (lambda x: {\"metadata\": x.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebc5c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. QA Prompt Template\n",
    "qa_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question using only the context below.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f85ad371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Create QA chain (RAG-style)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "qa_chain = qa_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34cac0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Full pipeline\n",
    "def ask_question(query):\n",
    "    # Step 1: Tag question (optional)\n",
    "    tags = tag_chain.invoke({\"query\": query})\n",
    "    print(\"Tags:\", tags)\n",
    "\n",
    "    # Step 2: Retrieve relevant documents\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # Step 3: QA over context\n",
    "    response = qa_chain.invoke({\"input\": query, \"context\": relevant_docs})\n",
    "    print(\"Full response:\", response)\n",
    "\n",
    "    # Step 4: Safe return\n",
    "    if isinstance(response, dict):\n",
    "        return response.get(\"output\") or response.get(\"answer\") or response.get(\"result\") or response\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb60d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: {'metadata': 'company: tesla\\nyear: 2024'}\n",
      "Full response: content=\"I don't know.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 211, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bf9YEceQFp13PiMefNyHzKFwMhNHI', 'finish_reason': 'stop', 'logprobs': None} id='run--1c8851f5-7d5e-4553-8d4d-0a747cf68e3a-0' usage_metadata={'input_tokens': 211, 'output_tokens': 5, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Answer: content=\"I don't know.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 211, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bf9YEceQFp13PiMefNyHzKFwMhNHI', 'finish_reason': 'stop', 'logprobs': None} id='run--1c8851f5-7d5e-4553-8d4d-0a747cf68e3a-0' usage_metadata={'input_tokens': 211, 'output_tokens': 5, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Example usage\n",
    "question = \"What all products did tesla launched in 2024?\"\n",
    "print(\"Answer:\", ask_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted tags: {\n",
      "  \"company\": \"Tesla\",\n",
      "  \"year\": \"2024\"\n",
      "}\n",
      "Answer: I don't know.\n",
      "Final answer: I don't know.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69623a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
