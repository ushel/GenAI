{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8039aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.document import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a463098",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffd36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare and split documents\n",
    "loader = TextLoader(\"data.txt\")  # <- replace with your file\n",
    "document = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cca117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Embed and persist vector store\n",
    "persist_dir = \"./db\"\n",
    "db = Chroma.from_documents(split_docs, embedding=OpenAIEmbeddings(), persist_directory=persist_dir)\n",
    "db.persist()\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78369f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Setup LLMs and prompts\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Extract structured metadata as JSON with fields like \"company\" and \"year\" from the question below:\\n\\n{query}\"\"\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Use only the context below to answer the question.\n",
    "If the answer is not directly in the context, use reasoning to infer a likely but informed answer.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e076996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted tags: {\n",
      "    \"company\": \"Tesla\",\n",
      "    \"year\": \"2024\"\n",
      "}\n",
      "Answer: Based on the context provided, Tesla is likely planning to continue with multiple product launches, software upgrades, and global manufacturing expansion in the mid of 2024.\n",
      "Final answer: Based on the context provided, Tesla is likely planning to continue with multiple product launches, software upgrades, and global manufacturing expansion in the mid of 2024.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query: str) -> str:\n",
    "    # Tag extraction\n",
    "    tag_response = llm(tag_prompt.format_prompt(query=query).to_messages())\n",
    "    tags_text = tag_response.content.strip()\n",
    "\n",
    "    # You can parse tags_text as JSON if you want structured tags\n",
    "    print(\"Extracted tags:\", tags_text)\n",
    "\n",
    "    # Retrieve docs\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    combined_context = \"\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "    # QA\n",
    "    qa_response = llm(qa_prompt.format_prompt(input=query, context=combined_context).to_messages())\n",
    "\n",
    "    print(\"Answer:\", qa_response.content)\n",
    "    return qa_response.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"what is tesla planning in mid of 2024\"\n",
    "    answer = ask_question(question)\n",
    "    print(\"Final answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcb31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
