{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8039aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.document import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a463098",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ae4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def download_pdf(url, local_path):\n",
    "    response = requests.get(url)\n",
    "    with open(local_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Example\n",
    "url = \"https://openreview.net/pdf?id=VtmBAGCN7o\"\n",
    "local_pdf = \"temp.pdf\"\n",
    "\n",
    "download_pdf(url, local_pdf)\n",
    "\n",
    "# Load with LangChain\n",
    "loader = PyPDFLoader(local_pdf)\n",
    "docs = loader.load()\n",
    "\n",
    "# Optional: clean up after use\n",
    "# os.remove(local_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffd36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare and split documents\n",
    "# loader = TextLoader(\"data.txt\")  # <- replace with your file\n",
    "# document = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cca117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/qyjb36g92fs3ztdqk120mmkw0000gn/T/ipykernel_1461/3174094603.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  db = Chroma.from_documents(split_docs, embedding=OpenAIEmbeddings(), persist_directory=persist_dir)\n",
      "/var/folders/s8/qyjb36g92fs3ztdqk120mmkw0000gn/T/ipykernel_1461/3174094603.py:4: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "# 2. Embed and persist vector store\n",
    "persist_dir = \"./db\"\n",
    "db = Chroma.from_documents(split_docs, embedding=OpenAIEmbeddings(), persist_directory=persist_dir)\n",
    "db.persist()\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78369f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Setup LLMs and prompts\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Extract structured metadata as JSON from the question below:\\n\\n{query}\"\"\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Use only the context below to answer the question.\n",
    "If the answer is not directly in the context, use reasoning to infer a likely but informed answer.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e076996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted tags: {\n",
      "  \"company\": null,\n",
      "  \"year\": null\n",
      "}\n",
      "Answer: Based on the context provided, it is not possible to list down all the papers referred to in the article with author names and paper titles. The context mentions a long list of names of individuals who reviewed and edited the paper, contributed to the evaluation metric design, helped with experiments, and more. However, specific paper titles and author names are not mentioned in the context.\n",
      "Final answer: Based on the context provided, it is not possible to list down all the papers referred to in the article with author names and paper titles. The context mentions a long list of names of individuals who reviewed and edited the paper, contributed to the evaluation metric design, helped with experiments, and more. However, specific paper titles and author names are not mentioned in the context.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query: str) -> str:\n",
    "    # Tag extraction\n",
    "    tag_response = llm(tag_prompt.format_prompt(query=query).to_messages())\n",
    "    tags_text = tag_response.content.strip()\n",
    "\n",
    "    # You can parse tags_text as JSON if you want structured tags\n",
    "    print(\"Extracted tags:\", tags_text)\n",
    "\n",
    "    # Retrieve docs\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    combined_context = \"\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "    # QA\n",
    "    qa_response = llm(qa_prompt.format_prompt(input=query, context=combined_context).to_messages())\n",
    "\n",
    "    print(\"Answer:\", qa_response.content)\n",
    "    return qa_response.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"can you list down all the papers refer in the article with author name and name of paper\"\n",
    "    answer = ask_question(question)\n",
    "    print(\"Final answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcb31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
