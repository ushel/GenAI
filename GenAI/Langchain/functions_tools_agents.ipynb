{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00252189",
   "metadata": {},
   "source": [
    "Main use cases using OpenAI functions for Tagging and Extraction \n",
    "\n",
    "This allows us to  extract structured data from unstructured text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf84a5c",
   "metadata": {},
   "source": [
    "Tagging:-\n",
    "\n",
    "We have seen the LLM, given a function description, select arguments from the input text, generate a structured output forming a function call.\n",
    "\n",
    "More generally, the LLM can evaluated the input text and generated structured output.\n",
    "\n",
    "\n",
    "Text ---> LLM ----> {\n",
    "           ^             Sentiment: Positive\n",
    "           |             language: spanish\n",
    "           |         }\n",
    "      Structured\n",
    "      Description\n",
    "\n",
    "\n",
    "Here we pass in unstructured text along with some structured description, and then we use the LLM to generate some structured output to reason over that input text\n",
    "\n",
    "and create some response response in the format of the structured description that we pass in.\n",
    "\n",
    "Here in above eg, we know we have been generating an object that has a sentiment of the text and also has a tag for the language of the text.\n",
    "\n",
    "So we pass in a piece of text we will pass in a structure description saying hey extract some sentiment, extract some language, and the LLM will \n",
    "\n",
    "reason over that text and respond with am object that has a sentiments tag and a language tag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a36e92e",
   "metadata": {},
   "source": [
    "Extraction \n",
    "\n",
    "1. When given an input Json schema, the LLM gas been fine tuned to find and fill the parameters of that schema.\n",
    "\n",
    "2. The capability is not limited to function schema.\n",
    "\n",
    "3. This can be used for general purpose extraction.\n",
    "\n",
    "\n",
    "Text ----> LLM ----> [{ ...\n",
    "            ^            first_name: lang,\n",
    "            |            last_name: chain,\n",
    "            |            language: python\n",
    "            |          },\n",
    "            |         ]\n",
    "        Structured \n",
    "        Description\n",
    "\n",
    "\n",
    "In extraction, we are going to be extracting specific entities from the text. \n",
    "\n",
    "These entities are also represented by a structure description.\n",
    "\n",
    "But rather than using LLM to reason over the text and respond with a single output in this structure description.\n",
    "\n",
    "We are using LLM to look over the text and extract a list of these elements.\n",
    "\n",
    "eg look over an article and extract the list of papers that are mentioned in articles.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3561a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f567cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84785c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List   # to help us with type hints\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1df699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pydantic model\n",
    "\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description = \"Sentiment of text, should be `pos`, `neg` or `neutral`\")\n",
    "    language: str = Field(description = \"Language of the text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6c8376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/qyjb36g92fs3ztdqk120mmkw0000gn/T/ipykernel_2244/1725091243.py:1: LangChainDeprecationWarning: The function `_convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  convert_pydantic_to_openai_function(Tagging)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'Sentiment of text, should be `pos`, `neg` or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'Language of the text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f60fe",
   "metadata": {},
   "source": [
    "Here we got json block of function which is going to pass to openai as openai can only take functions in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30914f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfa1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/qyjb36g92fs3ztdqk120mmkw0000gn/T/ipykernel_2244/3583057845.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(temperature = 0)\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a72644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc6ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\" Think carefully, and them tag the text as instructed\"),\n",
    "    (\"user\",\"{input}\")   \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119be12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions = tagging_functions\n",
    "    function_call = {\"name\":\"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eddd2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3dd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfc0964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"pos\",\"language\":\"en\"}', 'name': 'Tagging'}}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 101, 'total_tokens': 120, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run--d7b134b6-8546-4577-8a23-953e42d4b0cd-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(json.dumps(response.model_dump(),indent=2))\n",
    "# json.dumps(tagging_chain.invoke({\"input\":\"I love langchain\"}).model_dump(),indent=2)\n",
    "tagging_chain.invoke({\"input\":\"I love langchain\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab2d1c5",
   "metadata": {},
   "source": [
    "Here we can see the function call is there arguments that are passes in and we can see that the sentiment is positive and language is english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ba6180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"neg\",\"language\":\"it\"}', 'name': 'Tagging'}}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 104, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run--0c4506bc-e597-4701-835d-6a03eda437ec-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\":\"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21278b",
   "metadata": {},
   "source": [
    "Here we can see the function call is there arguments that are passes in and we can see that the sentiment is negative and language is italian.\n",
    "\n",
    "here we can see output format is kind of nested and we know that we are always going to be extracting the structure and so what we really want to do\n",
    "\n",
    "is add an output parser that takes in this AI message and basically pares out the JSON and just says that because that's the only interesting thing here we already\n",
    "\n",
    "know that we are going to call this function, so \n",
    "\n",
    "the fact that content is null, that not interesting to us.\n",
    "\n",
    "the fact that there's a function call that's made, that not interesting to us.\n",
    "\n",
    "we are forcing to do that.\n",
    "\n",
    "The fact that it's calling tagging function, also not interesting to us because we know that it's going to call tagging function because we forced it to.\n",
    "\n",
    "Here we what really want is just the values of arguments, which is JSON block and it will be really convenient if that was parsed into JSON because it's JSON\n",
    "\n",
    "in this JSON block and we want to be able to use the individual elements.\n",
    "\n",
    "we can use Output parser, in chain that would help us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c7ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47beaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee78156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\":\"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b228e4",
   "metadata": {},
   "source": [
    "here we only got parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b3e0f",
   "metadata": {},
   "source": [
    "Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4f34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description = \"Person's name\")\n",
    "    age: Optional[int] = Field(description = \"Person's age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2451fe",
   "metadata": {},
   "source": [
    "we want to extract list of person objects so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d66e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description= \"List of info about people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877bc87",
   "metadata": {},
   "source": [
    "This Information class will be pass to opneai function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e883d656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'properties': {'people': {'description': 'List of info about people',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': \"Person's name\", 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"Person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51a4eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions= extraction_functions, function_call={\"name\":\"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d2376b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 96, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--66c89739-8567-48b3-9b4c-891eb5b22684-0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30, his mom is martha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2fa2b",
   "metadata": {},
   "source": [
    "Here we got all the parameters for the person, but considering martha, age is showing null, we can probably do better by forcing model to respond in more educated way.\n",
    "\n",
    "By adding prompt tht will tell the Language model to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b1b0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")      \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b112a",
   "metadata": {},
   "source": [
    "This will allow language model to not respond always to makeup age equals 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9613f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f22b8518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 113, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2ff58208-27f5-42a2-88a2-234308d75f76-0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\":\"Joe is 30, his mom is martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ec29a",
   "metadata": {},
   "source": [
    "we can parse this ai message to some structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f684d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\":\"Joe is 30, his mom is martha\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a19257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
